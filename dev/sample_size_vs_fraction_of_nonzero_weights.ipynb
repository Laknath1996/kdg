{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Created on Thu Dec 09 2021 5:59:36 AM\n",
    "# Author: Ashwin De Silva (ldesilv2@jhu.edu)\n",
    "# Objective: Implements the KDN class\n",
    "#\n",
    "\n",
    "# import standard libraries\n",
    "from sklearn.utils.validation import check_array, check_X_y\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class kdn():\n",
    "    def __init__(\n",
    "        self,\n",
    "        network,\n",
    "        k=1,\n",
    "        polytope_compute_method=\"all\",\n",
    "        weighting_method=\"lin\",\n",
    "        T=2,\n",
    "        c=1,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Kernel Density Network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        network : Keras Model\n",
    "            trained neural network model\n",
    "        k : int, optional\n",
    "            bias tuning parameter, by default 1\n",
    "        polytope_compute_method : str, optional\n",
    "            select the polytope compute method, by default 'all'\n",
    "        T : int, optional\n",
    "            polytope size threshold, by default 2\n",
    "        c : int, optional\n",
    "            weight tuning parameter, by default 1\n",
    "        weighting : bool, optional\n",
    "            select the weighting scheme, by default True\n",
    "        verbose : bool, optional\n",
    "            display meta data, by default True\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.polytope_means = {}\n",
    "        self.polytope_cov = {}\n",
    "        self.network = network\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.polytope_compute_method = polytope_compute_method\n",
    "        self.T = T\n",
    "        self.weighting_method = weighting_method\n",
    "        self.bias = {}\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # total number of layers in the NN\n",
    "        self.total_layers = len(self.network.layers)\n",
    "\n",
    "        # get the layer sizes of each layer\n",
    "        self.network_shape = []\n",
    "        for layer in network.layers:\n",
    "            self.network_shape.append(layer.output_shape[-1])\n",
    "\n",
    "        # get the weights and biases of the trained MLP\n",
    "        self.weights = {}\n",
    "        self.biases = {}\n",
    "        for i in range(len(self.network.layers)):\n",
    "            weight, bias = self.network.layers[i].get_weights()\n",
    "            self.weights[i], self.biases[i] = weight, bias.reshape(1, -1)\n",
    "\n",
    "    def _get_polytope_memberships(self, X):\n",
    "        r\"\"\"\n",
    "        Obtain the polytope ID of each input sample\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix.\n",
    "        \"\"\"\n",
    "        polytope_memberships = []\n",
    "        last_activations = X\n",
    "\n",
    "        # Iterate through neural network manually, getting node activations at each step\n",
    "        for layer_id in range(self.total_layers):\n",
    "            weights, bias = self.network.layers[layer_id].get_weights()\n",
    "\n",
    "            # Calculate new activations based on input to this layer\n",
    "            preactivation = np.matmul(last_activations, weights) + bias\n",
    "\n",
    "            # get list of activated nodes in this layer\n",
    "            if layer_id == self.total_layers - 1:\n",
    "                binary_preactivation = (preactivation > 0.5).astype(\"int\")\n",
    "            else:\n",
    "                binary_preactivation = (preactivation > 0).astype(\"int\")\n",
    "\n",
    "            if self.polytope_compute_method == \"pl\":\n",
    "                # determine the polytope memberships only based on the penultimate layer (uncomment )\n",
    "                if layer_id == self.total_layers - 2:\n",
    "                    polytope_memberships.append(binary_preactivation)\n",
    "\n",
    "            if self.polytope_compute_method == \"all\":\n",
    "                # determine the polytope memberships only based on all the FC layers (uncomment)\n",
    "                if layer_id < self.total_layers - 1:\n",
    "                    polytope_memberships.append(binary_preactivation)\n",
    "\n",
    "            # remove all nodes that were not activated\n",
    "            last_activations = preactivation * binary_preactivation\n",
    "\n",
    "        # Concatenate all activations for given observation\n",
    "        polytope_obs = np.concatenate(polytope_memberships, axis=1)\n",
    "        polytope_memberships = [\n",
    "            np.tensordot(\n",
    "                polytope_obs, 2 ** np.arange(0, np.shape(polytope_obs)[1]), axes=1\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.num_fc_neurons = polytope_obs.shape[\n",
    "            1\n",
    "        ]  # get the number of total FC neurons under consideration\n",
    "\n",
    "        return polytope_memberships\n",
    "\n",
    "    def _get_activation_pattern(self, polytope_id):\n",
    "        \"\"\"get the ReLU activation pattern given the polytope ID\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        polytope_id : int\n",
    "            polytope identifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            ReLU activation pattern (binary) corresponding to the given polytope ID\n",
    "        \"\"\"\n",
    "        binary_string = np.binary_repr(polytope_id, width=self.num_fc_neurons)[::-1]\n",
    "        return np.array(list(binary_string)).astype(\"int\")\n",
    "\n",
    "    def unit_step(self, x):\n",
    "        \"\"\"Computes the unit step function output for a given input\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : ndarray\n",
    "            Input array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            Unit step function output of the input array\n",
    "        \"\"\"\n",
    "        x = np.maximum(x, 0)\n",
    "        x[x > 0] = 1\n",
    "        return x\n",
    "\n",
    "    def compute_weights(self, X_, polytope_id):\n",
    "        \"\"\"compute weights based on the global network linearity measure\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_ : ndarray\n",
    "            Input data matrix\n",
    "        polytope_id : int\n",
    "            refernce polytope identifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            weights of each input sample in the input data matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        M_ref = self._get_activation_pattern(polytope_id)\n",
    "\n",
    "        start = 0\n",
    "        A = X_\n",
    "        A_ref = X_\n",
    "        d = 0\n",
    "        for l in range(len(self.network_shape)-1):\n",
    "            end = start + self.network_shape[l]\n",
    "            M_l = M_ref[start:end]\n",
    "            start = end\n",
    "            W, B = self.weights[l], self.biases[l]\n",
    "            pre_A = A @ W + B\n",
    "            A = np.maximum(0, pre_A)\n",
    "            pre_A_ref = A_ref @ W + B\n",
    "            A_ref = pre_A_ref @ np.diag(M_l) \n",
    "            d += np.linalg.norm(A - A_ref, axis=1, ord=2)\n",
    "\n",
    "        return np.exp(-self.c * d)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        r\"\"\"\n",
    "        Fits the kernel density network\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix.\n",
    "        y : ndarray\n",
    "            Output (i.e. response) data matrix.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.labels = np.unique(y)\n",
    "\n",
    "        feature_dim = X.shape[1]\n",
    "\n",
    "        mean_fractions = []\n",
    "        for label in self.labels:\n",
    "            self.polytope_means[label] = []\n",
    "            self.polytope_cov[label] = []\n",
    "\n",
    "            X_ = X[np.where(y == label)[0]]\n",
    "            polytope_memberships = self._get_polytope_memberships(X_)[0]\n",
    "            unique_polytope_ids = np.unique(\n",
    "                polytope_memberships\n",
    "            )  # get the unique polytopes\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Number of Polytopes : \", len(polytope_memberships))\n",
    "                print(\"Number of Unique Polytopes : \", len(unique_polytope_ids))\n",
    "\n",
    "            fractions = []  # store the polytope member counts\n",
    "\n",
    "            for (\n",
    "                idx\n",
    "            ) in range(\n",
    "                len(polytope_memberships)\n",
    "            ):  # fit Gaussians for each unique non-singleton polytopes\n",
    "\n",
    "                if self.weighting_method == \"lin\":\n",
    "                    # compute weights of the input data samples w.r.t reference polytope\n",
    "                    weights = self.compute_weights(X_, polytope_memberships[idx])\n",
    "                elif self.weighting_method == \"fm\":\n",
    "                    ########### FM (will be depricated) ################\n",
    "                    a_native = self._get_activation_pattern(polytope_memberships[idx])\n",
    "                    weights = []\n",
    "                    for member_polytope_id in polytope_memberships:\n",
    "                        a_foreign = self._get_activation_pattern(member_polytope_id)\n",
    "\n",
    "                        match_status = a_foreign == a_native\n",
    "                        match_status = match_status.astype(\"int\")\n",
    "\n",
    "                        if len(np.where(match_status == 0)[0]) == 0:\n",
    "                            weight = 1.0\n",
    "                        else:\n",
    "                            first_mismatch_idx = np.where(match_status == 0)[0][0]\n",
    "                            weight = first_mismatch_idx / self.num_fc_neurons\n",
    "\n",
    "                        weights.append(weight)\n",
    "                    weights = np.array(weights)\n",
    "                ########### FM (will be depricated) ################\n",
    "                else:\n",
    "                    weights = np.zeros((X_.shape[0],))\n",
    "                    weights[polytope_memberships == polytope_memberships[idx]] = 1\n",
    "\n",
    "                weights[weights < 1e-3] = 0  # set very small weights to zero\n",
    "\n",
    "                idx = np.where(weights > 0)[0]\n",
    "\n",
    "                polytope_size = len(idx)\n",
    "                fractions.append(polytope_size/len(X_))\n",
    "\n",
    "                if (\n",
    "                    polytope_size < self.T\n",
    "                ):  # eliminate polytopes with too few samples within\n",
    "                    continue\n",
    "\n",
    "                scales = weights[idx] / np.max(weights[idx])\n",
    "\n",
    "                # apply weights to the data\n",
    "                X_tmp = X_[idx].copy()\n",
    "                polytope_mean_ = np.average(\n",
    "                    X_tmp, axis=0, weights=scales\n",
    "                )  # compute the weighted average of the samples\n",
    "                X_tmp -= polytope_mean_  # center the data\n",
    "\n",
    "                sqrt_scales = np.sqrt(scales).reshape(-1, 1) @ np.ones(\n",
    "                    feature_dim\n",
    "                ).reshape(1, -1)\n",
    "                X_tmp *= sqrt_scales  # scale the centered data with the square root of the weights\n",
    "\n",
    "                # compute the covariance matrix of the underlying Gaussian using Ledoit-Wolf estimator\n",
    "\n",
    "                covariance_model = LedoitWolf(assume_centered=True)\n",
    "                covariance_model.fit(X_tmp)\n",
    "                polytope_cov_ = covariance_model.covariance_ * len(scales) / sum(scales)\n",
    "\n",
    "                # store the mean and covariances\n",
    "                self.polytope_means[label].append(polytope_mean_)\n",
    "                self.polytope_cov[label].append(polytope_cov_)\n",
    "\n",
    "            mean_fractions.append(np.mean(fractions))\n",
    "\n",
    "        return mean_fractions\n",
    "\n",
    "            # ## calculate bias for each label\n",
    "            # likelihoods = np.zeros((np.size(X_, 0)), dtype=float)\n",
    "\n",
    "            # for polytope_idx, _ in enumerate(self.polytope_means[label]):\n",
    "            #     likelihoods += np.nan_to_num(self._compute_pdf(X_, label, polytope_idx))\n",
    "\n",
    "            # likelihoods /= X_.shape[0]\n",
    "            # self.bias[label] = np.min(likelihoods) / (self.k * X_.shape[0])\n",
    "\n",
    "    def _compute_pdf(self, X, label, polytope_idx):\n",
    "        \"\"\"compute the likelihood for the given data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix\n",
    "        label : int\n",
    "            class label\n",
    "        polytope_idx : int\n",
    "            polytope identifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            likelihoods\n",
    "        \"\"\"\n",
    "        polytope_mean = self.polytope_means[label][polytope_idx]\n",
    "        polytope_cov = self.polytope_cov[label][polytope_idx]\n",
    "\n",
    "        var = multivariate_normal(\n",
    "            mean=polytope_mean, cov=polytope_cov, allow_singular=True\n",
    "        )\n",
    "\n",
    "        likelihood = var.pdf(X)\n",
    "        return likelihood\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        r\"\"\"\n",
    "        Calculate posteriors using the kernel density forest.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix.\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "\n",
    "        likelihoods = np.zeros((np.size(X, 0), len(self.labels)), dtype=float)\n",
    "\n",
    "        for ii, label in enumerate(self.labels):\n",
    "            total_polytopes = len(self.polytope_means[label])\n",
    "            for polytope_idx, _ in enumerate(self.polytope_means[label]):\n",
    "                likelihoods[:, ii] += np.nan_to_num(\n",
    "                    self._compute_pdf(X, label, polytope_idx)\n",
    "                )\n",
    "\n",
    "            likelihoods[:, ii] = likelihoods[:, ii] / total_polytopes\n",
    "            likelihoods[:, ii] += min(self.bias.values())\n",
    "\n",
    "        proba = (likelihoods.T / (np.sum(likelihoods, axis=1) + 1e-100)).T\n",
    "        return proba\n",
    "\n",
    "    def predict_proba_nn(self, X):\n",
    "        r\"\"\"\n",
    "        Calculate posteriors using the vanilla NN\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix.\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "\n",
    "        proba = self.network.predict(X)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        r\"\"\"\n",
    "        Perform inference using the kernel density forest.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Input data matrix.\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from kdg.utils import generate_spirals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN parameters\n",
    "X_val, y_val = generate_spirals(500, noise=0.8, n_class=2)\n",
    "compile_kwargs = {\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"optimizer\": keras.optimizers.Adam(3e-4),\n",
    "}\n",
    "callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=True)\n",
    "fit_kwargs = {\n",
    "    \"epochs\": 300,\n",
    "    \"batch_size\": 64,\n",
    "    \"verbose\": False,\n",
    "    \"validation_data\": (X_val, keras.utils.to_categorical(y_val)),\n",
    "    \"callbacks\": [callback],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network architecture\n",
    "def getNN():\n",
    "    network_base = keras.Sequential()\n",
    "    initializer = keras.initializers.GlorotNormal(seed=0)\n",
    "    network_base.add(keras.layers.Dense(10, activation=\"relu\", kernel_initializer=initializer, input_shape=(2,)))\n",
    "    network_base.add(keras.layers.Dense(10, activation=\"relu\", kernel_initializer=initializer))\n",
    "    network_base.add(keras.layers.Dense(10, activation=\"relu\", kernel_initializer=initializer))\n",
    "    network_base.add(keras.layers.Dense(5, activation=\"relu\", kernel_initializer=initializer))\n",
    "    network_base.add(keras.layers.Dense(units=2, activation=\"softmax\", kernel_initializer=initializer))\n",
    "    network_base.compile(**compile_kwargs)\n",
    "    return network_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00245: early stopping\n",
      "[1.0, 1.0]\n",
      "Epoch 00208: early stopping\n",
      "[1.0, 0.9952000000000001]\n",
      "Epoch 00011: early stopping\n",
      "[1.0, 1.0]\n",
      "Epoch 00143: early stopping\n",
      "[0.9974879999999999, 0.9933919999999999]\n",
      "[0.7754319999999999, 0.7603800000000001]\n",
      "Epoch 00179: early stopping\n",
      "[0.3694912, 0.39666336]\n",
      "Epoch 00129: early stopping\n",
      "[0.34009652, 0.28146935999999995]\n"
     ]
    }
   ],
   "source": [
    "sample_sizes = [10, 50, 100, 500, 1000, 5000, 10000]\n",
    "fractions = []\n",
    "for n in sample_sizes:\n",
    "    # create training, validation, and testing data\n",
    "    X, y = generate_spirals(n, noise=0.8, n_class=2)\n",
    "\n",
    "    # train Vanilla NN\n",
    "    nn = getNN()\n",
    "    history = nn.fit(X, keras.utils.to_categorical(y), **fit_kwargs)\n",
    "\n",
    "    model_kdn = kdn(\n",
    "        network=nn,\n",
    "        polytope_compute_method='all',\n",
    "        weighting_method='lin',\n",
    "        k=1e-5,\n",
    "        c=1, \n",
    "        verbose=False\n",
    "    )\n",
    "    mean_fractions = model_kdn.fit(X, y)\n",
    "    print(mean_fractions)\n",
    "    fractions.append(mean_fractions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(sample_sizes, fractions)\n",
    "ax.set_xlabel(r\"$n$\", fontsize=15)\n",
    "ax.set_ylabel(r\"$\\frac{k}{n}$\", fontsize=15)\n",
    "# ax.set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d95b061de94e11b297f10cd4fe2e3f784f4933b278fd1968b1b57b743177f15"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('kdg_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
